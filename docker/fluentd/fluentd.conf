# tail 입력 플러그인을 사용하여 Suricata가 실시간으로 기록하는 JSON 로그 파일(/var/log/suricata/eve.json)을 지속적으로 읽는다.
<source>
  @type tail
  @id suricata_logs
  tag suricata.*  # 입력 이벤트에 tag를 부여하여 이후 필터나 출력(match)에서 해당 로그를 구분하고 선택적으로 처리할 수 있도록 한다.
  path /var/log/suricata/eve.json  # Suricata가 JSON 형식으로 출력하는 주요 이벤트 로그 파일의 경로를 지정한다.
  pos_file /fluentd/state/suricata.pos  # 수집 위치를 기록하는 파일 경로로, Fluentd가 중단 후 재시작 시 중복 수집을 방지하고 마지막 읽은 위치부터 다시 시작할 수 있도록 한다.

  <parse>
    @type json  # 로그 파일의 포맷이 JSON이므로 JSON 파서를 지정하여 이벤트를 구조화된 형식으로 변환한다.
  </parse>

  read_from_head true  # Fluentd가 처음 시작될 때 로그 파일의 처음부터(head) 읽을지 여부를 결정하며, true이면 과거 로그 전체를 처음부터 읽는다.
</source>

# 수집된 Suricata 로그 이벤트에 대해 필터를 적용하여 필요한 필드만 추출하거나 새로운 필드를 추가하고, 가공된 로그 형태로 변환하여 후속 처리 시스템으로 전송 가능하도록 준비한다.
<filter suricata.**>
  @type record_transformer
  @id transform_suricata_logs
  enable_ruby true  # Ruby 표현식을 허용하여 로그 필드 내 계산이나 변환을 유연하게 처리할 수 있도록 설정한다.

  <record>
    timestamp ${time.strftime('%Y-%m-%dT%H:%M:%S%z')}  # 현재 Fluentd 서버 기준의 시간(timestamp)을 ISO8601 형식으로 문자열 변환하여 기록 시점을 명시적으로 추가한다.
    src_ip ${record["src_ip"]}  # 수집된 JSON 로그에서 출발지 IP 필드(src_ip)를 추출하여 로그 필드로 추가한다.
    dest_ip ${record["dest_ip"]}  # 수집된 JSON 로그에서 목적지 IP 필드(dest_ip)를 추출하여 로그 필드로 추가한다.
    action ${record["action"]}  # Suricata 이벤트의 행위(예: alert, drop 등)를 나타내는 action 필드를 추출하여 로그 필드로 추가한다.
    event_type ${record["event_type"]}  # Suricata 이벤트의 유형(alert, flow, dns 등)을 나타내는 필드를 추출하여 로그 필드로 추가한다.
    log_data_jsonb ${Yajl.dump(record)}  # 전체 로그 이벤트(JSON 오브젝트)를 문자열(JSONB 형식으로) 직렬화하여 PostgreSQL 또는 기타 시스템에서 JSON 컬럼으로 저장 가능하도록 한다.
  </record>
</filter>

# 위에서 가공된 로그 데이터를 HTTP POST 방식으로 외부 API 서버(Axum 등)에 전송하며, JSON 형식으로 직렬화된 로그를 지정된 엔드포인트로 실시간 스트리밍 형태로 전달한다.
<match suricata.**>
  @type http
  @id http_output
  endpoint http://localhost:3000  # 로그를 전송할 REST API 서버 주소이며, 여기서는 동일 호스트 내 Axum API 서버의 포트 3000을 대상으로 한다.
  http_method post  # HTTP 요청 방식은 POST이며, 로그 데이터를 본문(body)에 포함하여 전송한다.
  content_type application/json  # 전송되는 데이터의 MIME 타입을 JSON(application/json)으로 지정하여 수신 서버가 JSON으로 인식하도록 한다.

  <format>
    @type json  # 로그 이벤트를 JSON 형식으로 포맷팅하여 전송 포맷을 명시한다.
  </format>

  <buffer>
    @type memory  # 로그를 일시적으로 저장할 버퍼 저장소로 메모리(memory)를 사용하여 빠른 처리 성능을 보장한다.
    flush_interval 5s  # 버퍼에 저장된 로그를 5초마다 주기적으로 전송하며, 짧은 주기로 실시간성(log latency)을 확보한다.
    flush_at_shutdown true  # Fluentd가 종료되기 직전에 남아 있는 버퍼 내용을 모두 전송하도록 설정하여 데이터 손실을 방지한다.
    chunk_limit_size 4m  # 버퍼의 각 청크(chunk) 크기를 최대 4MB로 제한하여 네트워크 트래픽 및 API 서버 처리 부하를 조절한다.
    retry_max_times 5  # 로그 전송 실패 시 최대 재시도 횟수를 5회로 제한하지만 아래 설정으로 무시된다.
    retry_forever true  # 로그 전송 실패 시 재시도를 무한 반복하여 로그 유실을 방지하며, 외부 API 서버가 일시적 장애여도 자동 복구된다.
    retry_wait 10s  # 재시도 간 간격은 10초로 설정하여 지나치게 빠른 재시도로 인해 서버에 부하가 가지 않도록 조절한다.
  </buffer>
</match>
